{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56e52d2c-e7a6-478d-b846-e6594bd8564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import confluent_kafka\n",
    "from confluent_kafka import KafkaError, KafkaException\n",
    "\n",
    "\n",
    "class KafkaObject(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bootstrap_servers,\n",
    "            buffering_max_messages=2000000,\n",
    "            session_timeout=1740000,\n",
    "            max_pol_interval_ms=1750000,\n",
    "            heartbeat_interval_ms=30000,\n",
    "            connections_max_handle_ms=54000000,\n",
    "            off_set_reset='earliest'\n",
    "    ):\n",
    "        self.bootstrap_servers = bootstrap_servers\n",
    "        self.producer_conf = {\n",
    "            'bootstrap.servers': self.bootstrap_servers,\n",
    "            'queue.buffering.max.messages': buffering_max_messages\n",
    "        }\n",
    "        self.consumer_conf = {\n",
    "            'bootstrap.servers': self.bootstrap_servers,\n",
    "            'session.timeout.ms': session_timeout,\n",
    "            'heartbeat.interval.ms': heartbeat_interval_ms,\n",
    "            'connections.max.idle.ms': connections_max_handle_ms,\n",
    "            'max.poll.interval.ms': max_pol_interval_ms,\n",
    "            'fetch.wait.max.ms': 1000,\n",
    "            'socket.keepalive.enable': 'true',\n",
    "            'default.topic.config': {\n",
    "                'auto.offset.reset': off_set_reset\n",
    "            }\n",
    "        }\n",
    "        logging.basicConfig(level=logging.DEBUG)\n",
    "        self.logger = logging.getLogger('kafka-object')\n",
    "\n",
    "    def handler(self, msg, mem_obj, aces_metrics):\n",
    "        json_result = json.loads(msg.value().decode())\n",
    "        # dict_keys(['labels', 'name', 'timestamp', 'value'])\n",
    "        result = json_result[\"labels\"]\n",
    "        metric_name = result[\"__name__\"]\n",
    "        if metric_name.startswith(\"container\"):\n",
    "            if \"pod\" in result.keys():\n",
    "                query = mem_obj.insert_pod_metric(\n",
    "                    node_id=\"node1\",\n",
    "                    pod_id=result[\"pod\"],\n",
    "                    name=metric_name,\n",
    "                    timeseries_origin=\"metrics_values\"\n",
    "                )\n",
    "                mem_obj.bolt_transaction(query)\n",
    "                aces_metrics.insert_metrics(\n",
    "                    table_name=\"metrics_values\",\n",
    "                    time=json_result['timestamp'],\n",
    "                    metric=metric_name,\n",
    "                    pod=result['pod'],\n",
    "                    value=json_result['value'],\n",
    "                    node=\"node1\"\n",
    "                )\n",
    "                \n",
    "                \n",
    "    def producer(\n",
    "            self,\n",
    "            msg,\n",
    "            topic\n",
    "    ):\n",
    "        messages_overflow = 0\n",
    "        producer = confluent_kafka.Producer(**self.producer_conf)\n",
    "        try:\n",
    "            producer.produce(topic, value=json.dumps(msg))\n",
    "        except BufferError as e:\n",
    "            messages_overflow += 1\n",
    "\n",
    "        # checking for overflow\n",
    "        self.logger.error(f'BufferErrors: {messages_overflow}')\n",
    "        producer.flush()\n",
    "\n",
    "    def consumer(\n",
    "            self,\n",
    "            list_of_topics,\n",
    "            group_id,\n",
    "            mem_obj, aces_metrics\n",
    "    ):\n",
    "        consumer_config = self.consumer_conf\n",
    "        consumer_config['group.id'] = group_id\n",
    "        consumer = confluent_kafka.Consumer(**consumer_config)\n",
    "        consumer.subscribe(list_of_topics)\n",
    "\n",
    "        while True:\n",
    "            msg = consumer.poll()\n",
    "            if msg is None:\n",
    "                continue\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition event\n",
    "                    sys.stderr.write(\n",
    "                        '%% %s [%d] reached end at offset %d\\n' % (msg.topic(), msg.partition(), msg.offset()))\n",
    "                elif msg.error():\n",
    "                    # Error\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                self.handler(msg, mem_obj, aces_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70ef35e4-c0f6-4557-8fa9-403365347a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_base.demand import DemandGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca684b2c-0590-4749-89d4-dbe2958a5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timescaledb.client import AcesMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d41d8133-db29-4f49-b482-3add8a4cdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_obj = DemandGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19370a3c-52a9-41d0-b70f-a2c49c932550",
   "metadata": {},
   "outputs": [],
   "source": [
    "aces_metrics = AcesMetrics(\n",
    "    host=\"timescaledb\",\n",
    "    username=\"aces\",\n",
    "    database=\"aces\",\n",
    "    password=\"aces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78826ebb-e116-4e99-b864-484b9df7426b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kafka_obj = KafkaObject(\n",
    "    bootstrap_servers=\"broker:29092\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eccbf48-f8d3-409c-bfe0-84fdc02d2984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-22 15:24:07,592 - graph_base.base_client - INFO - Nodes created: 2 Rels created: 2\n",
      "2024-02-22 15:24:07,648 - graph_base.base_client - INFO - Nodes created: 1 Rels created: 2\n"
     ]
    },
    {
     "ename": "InterfaceError",
     "evalue": "cursor already closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkafka_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsumer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpan290292\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maces_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maces_metrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 104\u001b[0m, in \u001b[0;36mKafkaObject.consumer\u001b[0;34m(self, list_of_topics, group_id, mem_obj, aces_metrics)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m KafkaException(msg\u001b[38;5;241m.\u001b[39merror())\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maces_metrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 53\u001b[0m, in \u001b[0;36mKafkaObject.handler\u001b[0;34m(self, msg, mem_obj, aces_metrics)\u001b[0m\n\u001b[1;32m     46\u001b[0m query \u001b[38;5;241m=\u001b[39m mem_obj\u001b[38;5;241m.\u001b[39minsert_pod_metric(\n\u001b[1;32m     47\u001b[0m     node_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     pod_id\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpod\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     49\u001b[0m     name\u001b[38;5;241m=\u001b[39mmetric_name,\n\u001b[1;32m     50\u001b[0m     timeseries_origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics_values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m mem_obj\u001b[38;5;241m.\u001b[39mbolt_transaction(query)\n\u001b[0;32m---> 53\u001b[0m \u001b[43maces_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnode1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/horse/timescaledb/client.py:63\u001b[0m, in \u001b[0;36mAcesMetrics.insert_metrics\u001b[0;34m(self, table_name, time, metric, node, pod, value)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_metrics\u001b[39m(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m         table_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m         value\n\u001b[1;32m     62\u001b[0m ):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (time, metric, node, pod, value) VALUES (%s, %s, %s, %s, %s);\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_client()\n",
      "\u001b[0;31mInterfaceError\u001b[0m: cursor already closed"
     ]
    }
   ],
   "source": [
    "kafka_obj.consumer([\"metrics\"], group_id=\"pan290292\", mem_obj=this_obj, aces_metrics=aces_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56893795-3247-4b3e-a21a-774540e77871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
